{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data set - LTI system\n",
    "An LTI system is excited by an uniform signal $X \\sim U[-1, 1]$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "pycharm": {
     "is_executing": false,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "from volterra import *\n",
    "\n",
    "# system parameters\n",
    "sys_imp_resp_length = 20\n",
    "sys_impulse_response = np.linspace(10, 0.5, sys_imp_resp_length)\n",
    "sys_impulse_response = [1] * sys_imp_resp_length\n",
    "true_sys = LTISystem(sys_impulse_response)\n",
    "\n",
    "# noise signal parameters\n",
    "z_sigma = 0.1\n",
    "\n",
    "x_amp = 1\n",
    "\n",
    "# generate learning batch\n",
    "est_batch_size = 1000\n",
    "x_est = np.random.uniform(-x_amp, x_amp, est_batch_size)\n",
    "z_est = z_sigma * np.random.standard_normal(est_batch_size)\n",
    "y_est = true_sys.evaluate_output(x_est) + z_est\n",
    "\n",
    "# generate validation batch\n",
    "val_batch_size = 1000\n",
    "x_val = np.random.uniform(-x_amp, x_amp, val_batch_size)\n",
    "z_val = z_sigma * np.random.standard_normal(val_batch_size)\n",
    "y_val = true_sys.evaluate_output(x_val) + z_val"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Aggregation algorithm\n",
    "\n",
    "The algorithm aims to estimate Volterra model's parameters on an $\\ell_1$-ball of radius $R$. \n",
    "Since, we know the $\\ell_1$-norm of the true system's parameters we can choose optimal $R$.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "pycharm": {
     "is_executing": false,
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "<Figure size 960x720 with 1 Axes>"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from aggregation import *\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# model parameters\n",
    "model_order = 1\n",
    "model_memory_len = sys_imp_resp_length\n",
    "m = VolterraModel(model_order, model_memory_len)\n",
    "\n",
    "params = aggregation_for_volterra(m.dictionary, x_est, y_est, R=np.linalg.norm(sys_impulse_response, 1))\n",
    "m.set_parameters(params)\n",
    "\n",
    "y_aggr = m.evaluate_output(x_val)\n",
    "\n",
    "# plot data\n",
    "plt.rcParams['figure.dpi'] = 150\n",
    "plt.plot(y_aggr[:100])\n",
    "plt.plot(y_val[:100])\n",
    "plt.xlabel('t')\n",
    "plt.legend(['model', 'true system'])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Entropic descent on a probabilistic simplex\n",
    "\n",
    "To use this method we need following parameters:\n",
    "- $\\sigma_Z^2$ - variance of the noise signal\n",
    "- $R$ - radius of the $\\ell_1$-ball over which we estimate\n",
    "- $M$ - the system's output magnitude\n",
    "\n",
    "We also use a _scaling parameter_ that scales the stepsize - apparently the equation for its derivation doesn't work"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "pycharm": {
     "is_executing": false,
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "evalue": "<lambda>() takes 1 positional argument but 2 were given",
     "ename": "TypeError",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-3-86402909b85e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     23\u001b[0m \u001b[0mdictionary\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mVolterraDictionary\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_order\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel_memory_len\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minclude_constant_function\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minclude_constant_function\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m \u001b[0malg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mEntropicDescentAlgorithm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdictionary\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mR\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mR\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconstraint\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'simplex'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 25\u001b[0;31m \u001b[0mmodel_parameters\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0malg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_est\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_est\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstepsize_function\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     26\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m \u001b[0mm\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_parameters\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_parameters\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/dev/python_ml/sysid/entropic_descent.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, x, y, stepsize_function)\u001b[0m\n\u001b[1;32m     76\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mT\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     77\u001b[0m             \u001b[0mgradient\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompute_gradient\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 78\u001b[0;31m             \u001b[0mstepsize\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstepsize_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     79\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     80\u001b[0m             \u001b[0mtheta_i\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexp\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mstepsize\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mgradient\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: <lambda>() takes 1 positional argument but 2 were given"
     ],
     "output_type": "error"
    }
   ],
   "source": [
    "from entropic_descent import *\n",
    "\n",
    "z_var = z_sigma ** 2\n",
    "R = np.linalg.norm(sys_impulse_response, 1)\n",
    "M = np.max(np.abs(x_est))\n",
    "\n",
    "# model parameters\n",
    "model_order = 1\n",
    "model_memory_len = sys_imp_resp_length\n",
    "\n",
    "include_constant_function = False\n",
    "m = VolterraModel(model_order, model_memory_len, include_constant_function=include_constant_function)\n",
    "D = m.dictionary.size\n",
    "\n",
    "G_sq = R ** 2 * ((R + M) ** 2 + z_var)\n",
    "\n",
    "scaling_parameter = 10  # this is parameter for scaling the stepsize\n",
    "\n",
    "stepsize = scaling_parameter * np.sqrt(2 * np.log(D) / (G_sq * (est_batch_size + 1)))\n",
    "stepsize_function = lambda i: stepsize\n",
    "\n",
    "# FIXME copy doesnt work, dictionary instead of m.dictionary\n",
    "dictionary = VolterraDictionary(model_order, model_memory_len, include_constant_function=include_constant_function)\n",
    "alg = EntropicDescentAlgorithm(dictionary, R=R, constraint='simplex')\n",
    "model_parameters = alg.run(x_est, y_est, stepsize_function)\n",
    "\n",
    "m.set_parameters(model_parameters)\n",
    "                   \n",
    "y_ed = m.evaluate_output(x_val)\n",
    "\n",
    "# plot data\n",
    "plt.rcParams['figure.dpi'] = 150\n",
    "plt.plot(y_ed[:100])\n",
    "plt.plot(y_val[:100])\n",
    "plt.xlabel('t')\n",
    "plt.legend(['model', 'true system'])\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": false,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "x = [1] + [0] * 10\n",
    "plt.rcParams['figure.dpi'] = 150\n",
    "plt.plot(m.evaluate_output(x), 'bo')\n",
    "plt.plot(true_sys.evaluate_output(x), 'ro')\n",
    "plt.xlabel('t')\n",
    "plt.ylabel('impulse response')\n",
    "plt.legend(['model', 'true system'])\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Data set - LTI system with negative impulse response values\n",
    "An LTI system is excited by an uniform signal $X \\sim U[-1, 1]$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": false,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "from volterra import *\n",
    "\n",
    "# system parameters\n",
    "sys_imp_resp_length = 15\n",
    "sys_impulse_response = np.linspace(5, -5, sys_imp_resp_length)\n",
    "true_sys = LTISystem(sys_impulse_response)\n",
    "\n",
    "# noise signal parameters\n",
    "z_sigma = 0.01\n",
    "\n",
    "# generate learning batch\n",
    "est_batch_size = 1000\n",
    "x_est = np.random.uniform(-1, 1, est_batch_size)\n",
    "z_est = z_sigma * np.random.standard_normal(est_batch_size)\n",
    "y_est = true_sys.evaluate_output(x_est) + z_est\n",
    "\n",
    "# generate validation batch\n",
    "val_batch_size = 1000\n",
    "x_val = np.random.uniform(-1, 1, val_batch_size)\n",
    "z_val = z_sigma * np.random.standard_normal(val_batch_size)\n",
    "y_val = true_sys.evaluate_output(x_val) + z_val"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# Entropic descent on an $\\ell_1$-ball"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": false,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from entropic_descent import *\n",
    "\n",
    "z_var = z_sigma ** 2\n",
    "R = np.linalg.norm(sys_impulse_response, 1)\n",
    "M = R #np.max(np.abs(x_est))\n",
    "\n",
    "# model parameters\n",
    "model_order = 1\n",
    "model_memory_len = sys_imp_resp_length + 5\n",
    "\n",
    "include_constant_function = False\n",
    "dict_type='legendre_norm'\n",
    "#dict_type='standard'\n",
    "m = VolterraModel(model_order, model_memory_len, include_constant_function=include_constant_function, dict_type=dict_type)\n",
    "D = m.dictionary.size\n",
    "\n",
    "G_sq = R ** 2 * ((R + M) ** 2 + z_var)\n",
    "\n",
    "scaling_parameter = 1  # this is parameter for scaling the stepsize\n",
    "\n",
    "stepsize = scaling_parameter * np.sqrt(2 * np.log(2 * D) / (G_sq * (est_batch_size + 1)))\n",
    "stepsize_function = lambda i, gradient: stepsize\n",
    "\n",
    "#stepsize = scaling_parameter * np.sqrt(2 * np.log(2 * D) / (est_batch_size + 1))\n",
    "#stepsize_function = lambda i, gradient: stepsize / np.max(gradient)\n",
    "\n",
    "# FIXME copy doesnt work, dictionary instead of m.dictionary\n",
    "# dictionary = VolterraDictionary(model_order, model_memory_len, include_constant_function=include_constant_function)\n",
    "alg = EntropicDescentAlgorithm(m.dictionary, R=R, constraint='ball')\n",
    "model_parameters = alg.run(x_est, y_est, stepsize_function)\n",
    "\n",
    "m.set_parameters(model_parameters)\n",
    "                   \n",
    "x = [1] + [0] * (sys_imp_resp_length + 4)\n",
    "\n",
    "y_ed = m.evaluate_output(x_val)\n",
    "ed_imp_resp = m.evaluate_output(x)\n",
    "\n",
    "loss = 0.5 * np.mean(np.square(y_val - y_ed))\n",
    "loss_upper_bound = np.sqrt(G_sq * 2 * np.log(2 * D) / est_batch_size) + 0.5 * z_var\n",
    "print(\"         Empirical loss: {0}\".format(loss))\n",
    "print(\"Theoretical upper bound: {0}\".format(loss_upper_bound))\n",
    "\n",
    "# adaptive algorithm\n",
    "alg = AdaptiveEntropicDescentAlgorithm(m.dictionary, R=R, constraint='ball')\n",
    "model_parameters = alg.run(x_est, y_est, G_sq)\n",
    "\n",
    "m.set_parameters(model_parameters)\n",
    "                   \n",
    "y_ada_ed = m.evaluate_output(x_val)\n",
    "ada_ed_imp_resp = m.evaluate_output(x)\n",
    "\n",
    "loss = 0.5 * np.mean(np.square(y_val - y_ada_ed))\n",
    "print(\"Adaptive ED:\")\n",
    "print(\"         Empirical loss: {0}\".format(loss))\n",
    "\n",
    "\n",
    "# plot data\n",
    "plt.rcParams['figure.dpi'] = 150\n",
    "plt.plot(y_ed[:100])\n",
    "plt.plot(y_ada_ed[:100])\n",
    "plt.plot(y_val[:100])\n",
    "plt.xlabel('t')\n",
    "plt.legend(['ed', 'adaptive ed', 'true system'])\n",
    "plt.show()\n",
    "\n",
    "\n",
    "plt.rcParams['figure.dpi'] = 150\n",
    "plt.plot(ed_imp_resp, 'bx')\n",
    "plt.plot(ada_ed_imp_resp, 'mo')\n",
    "plt.plot(true_sys.evaluate_output(x), 'r.')\n",
    "plt.xlabel('t')\n",
    "plt.ylabel('impulse response')\n",
    "plt.legend(['ed', 'adaptive ed', 'true system'])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Aggregation algorithm\n",
    "\n",
    "The algorithm aims to estimate Volterra model's parameters on an $\\ell_1$-ball of radius $R$. \n",
    "Since, we know the $\\ell_1$-norm of the true system's parameters we can choose optimal $R$.  "
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from aggregation import *\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# model parameters\n",
    "model_order = 1\n",
    "model_memory_len = sys_imp_resp_length\n",
    "m = VolterraModel(model_order, model_memory_len)\n",
    "\n",
    "params = aggregation_for_volterra(m.dictionary, x_est, y_est, R=np.linalg.norm(sys_impulse_response, 1))\n",
    "m.set_parameters(params)\n",
    "\n",
    "y_aggr = m.evaluate_output(x_val)\n",
    "\n",
    "# plot data\n",
    "plt.rcParams['figure.dpi'] = 150\n",
    "plt.plot(y_aggr[:100])\n",
    "plt.plot(y_val[:100])\n",
    "plt.xlabel('t')\n",
    "plt.legend(['model', 'true system'])\n",
    "plt.show()\n",
    "\n",
    "x = [1] + [0] * (sys_imp_resp_length + 4)\n",
    "plt.rcParams['figure.dpi'] = 150\n",
    "plt.plot(m.evaluate_output(x), 'bx')\n",
    "plt.plot(true_sys.evaluate_output(x), 'r.')\n",
    "plt.xlabel('t')\n",
    "plt.ylabel('impulse response')\n",
    "plt.legend(['model', 'true system'])\n",
    "plt.show()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": false,
     "name": "#%% \n"
    }
   },
   "outputs": [],
   "source": [
    "num_of_experiments = 50\n",
    "\n",
    "x_amp = 1\n",
    "z_sigma = 0.001\n",
    "est_batch_size = 100\n",
    "val_batch_size = 1000\n",
    "\n",
    "# model parameters\n",
    "model_order = 3\n",
    "model_memory_len = sys_imp_resp_length + 5\n",
    "\n",
    "G_sq = R ** 2 * ((R + M) ** 2 + z_var)\n",
    "\n",
    "scaling_parameter = 1  # this is parameter for scaling the stepsize\n",
    "\n",
    "stepsize = scaling_parameter * np.sqrt(2 * np.log(2 * D) / (G_sq * (est_batch_size + 1)))\n",
    "stepsize_function = lambda i, gradient: stepsize\n",
    "\n",
    "avg_mse_in_experiment = np.zeros(num_of_experiments)\n",
    "\n",
    "for i in range(num_of_experiments):\n",
    "    # generate learning batch\n",
    "    x_est = np.random.uniform(-x_amp, x_amp, est_batch_size)\n",
    "    z_est = z_sigma * np.random.standard_normal(est_batch_size)\n",
    "    y_est = true_sys.evaluate_output(x_est) + z_est\n",
    "\n",
    "    # generate validation batch\n",
    "    x_val = np.random.uniform(-x_amp, x_amp, val_batch_size)\n",
    "    z_val = z_sigma * np.random.standard_normal(val_batch_size)\n",
    "    y_val = true_sys.evaluate_output(x_val) + z_val\n",
    "\n",
    "    m = VolterraModel(model_order, model_memory_len, include_constant_function=include_constant_function)\n",
    "    dictionary = VolterraDictionary(model_order, model_memory_len, include_constant_function=include_constant_function)\n",
    "    alg = EntropicDescentAlgorithm(dictionary, R=R, constraint='ball')\n",
    "    model_parameters = alg.run(x_est, y_est, stepsize_function)\n",
    "    m.set_parameters(model_parameters)\n",
    "    \n",
    "    y_ed = m.evaluate_output(x_val)\n",
    "    \n",
    "    avg_mse_in_experiment[i] = 0.5 * np.mean(np.square(y_val - y_ed))\n",
    "    \n",
    "    \n",
    "avg_loss = np.average(avg_mse_in_experiment)\n",
    "avg_loss_upper_bound = np.sqrt(G_sq * 2 * np.log(2 * D) / est_batch_size) + 0.5 * z_var\n",
    "print(\"           Average loss: {0}\".format(avg_loss))\n",
    "print(\"Theoretical upper bound: {0}\".format(avg_loss_upper_bound))\n",
    "\n",
    "plt.hist(avg_mse_in_experiment, bins=40)\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  },
  "pycharm": {
   "stem_cell": {
    "cell_type": "raw",
    "source": [],
    "metadata": {
     "collapsed": false
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}